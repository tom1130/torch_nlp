{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from konlpy.tag import Mecab\n",
    "\n",
    "from transformers import BertTokenizerFast\n",
    "from torchtext import transforms as T\n",
    "from torch.utils.data import Dataset, random_split\n",
    "\n",
    "computer = 'docker'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if computer=='docker':\n",
    "    train_data_path = '/root/share/data/train.csv'\n",
    "    test_data_path = '/root/share/data/test.csv'\n",
    "elif computer=='colab':\n",
    "    train_data_path = '/content/drive/MyDrive/commit_folder/chungwadae/torch_nlp/data/train.csv'\n",
    "    test_data_path = '/content/drive/MyDrive/commit_folder/chungwadae/torch_nlp/data/test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(train_data_path)\n",
    "test_data = pd.read_csv(test_data_path)\n",
    "\n",
    "train_data = train_data[train_data['data'].notnull()]\n",
    "train, valid = random_split(train_data, [len(train_data)-2000,2000])\n",
    "\n",
    "train = train_data.iloc[train.indices]\n",
    "valid = train_data.iloc[valid.indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizerFast.from_pretrained('kykim/bert-kor-base')\n",
    "mecab = Mecab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomTrainDataset(Dataset):\n",
    "  def __init__(self, df, tokenizer, tag):\n",
    "    self.labels = [label for label in df['category']]\n",
    "    df['data'] = df['data'].apply(self.tokenizer, tag=tag)\n",
    "    df['data'] = df['data'].apply(lambda x: ' '.join(x))\n",
    "    self.sentence = [\n",
    "        tokenizer(sentence, padding='max_length', max_length=300, truncation=True, return_tensors='pt')\n",
    "        for sentence in df['data']            \n",
    "    ]\n",
    "\n",
    "  def tokenizer(self, sentence, tag):\n",
    "    return tag.morphs(sentence)\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.labels)\n",
    "\n",
    "  def get_batch_labels(self, idx):\n",
    "    return np.array(self.labels[idx])\n",
    "\n",
    "  def get_batch_sentences(self, idx):\n",
    "    return self.sentence[idx]\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "\n",
    "    batch_sentence = self.get_batch_sentences(idx)\n",
    "    batch_y = self.get_batch_labels(idx)\n",
    "\n",
    "    return batch_sentence, batch_y\n",
    "\n",
    "class CustomTestDataset(Dataset):\n",
    "  def __init__(self, df, tokenizer, tag):\n",
    "    df['data'] = df['data'].apply(self.tokenizer, tag=tag)\n",
    "    df['data'] = df['data'].apply(lambda x: ' '.join(x))\n",
    "    self.sentence = [\n",
    "        tokenizer(sentence, padding='max_length', max_length=300, truncation=True, return_tensors='pt')\n",
    "        for sentence in df['data']            \n",
    "    ]\n",
    "\n",
    "  def tokenizer(self, sentence, tag):\n",
    "    return tag.morphs(sentence)\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.sentence)\n",
    "\n",
    "  def get_batch_sentences(self, idx):\n",
    "    return self.sentence[idx]\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "\n",
    "    batch_sentence = self.get_batch_sentences(idx)\n",
    "\n",
    "    return batch_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "train_dataset = CustomTrainDataset(train, tokenizer, mecab)\n",
    "valid_dataset = CustomTrainDataset(valid, tokenizer, mecab)\n",
    "test_dataset = CustomTestDataset(test_data, tokenizer, mecab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/root/share/data/train_dataset.pkl','wb') as f:\n",
    "    pickle.dump(train_dataset, f)\n",
    "\n",
    "with open('/root/share/data/valid_dataset.pkl','wb') as f:\n",
    "    pickle.dump(valid_dataset, f)\n",
    "    \n",
    "with open('/root/share/data/test_dataset.pkl','wb') as f:\n",
    "    pickle.dump(test_dataset, f)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
