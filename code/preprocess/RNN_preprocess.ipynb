{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기본 라이브러리\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from collections import Counter\n",
    "\n",
    "# tokenizer\n",
    "from konlpy.tag import Mecab\n",
    "\n",
    "# torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchtext\n",
    "from torchtext import transforms as T\n",
    "from torchtext.vocab import vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000\n",
      "5000\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('/root/share/data/train.csv')\n",
    "test = pd.read_csv('/root/share/data/test.csv')\n",
    "print(len(train))\n",
    "print(len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  \n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:5: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "# 필요 단어만 남기기\n",
    "train['data'] = train['data'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\")\n",
    "train = train[train['data'].notnull()]\n",
    "\n",
    "test['data'] = test['data'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\")\n",
    "\n",
    "stop_words = ['의','가','이','은','들','는','좀','잘','걍','과','도','를','으로','자','에','와','한','하다','을']\n",
    "# 조사 및 불필요 단어 제거 \n",
    "def tokenizer(sentence, tag):\n",
    "    return tag.morphs(sentence)\n",
    "mecab = Mecab()\n",
    "train['morph'] = train['data'].apply(tokenizer, tag=mecab)\n",
    "train['morph'] = train['morph'].apply(lambda xs: [x for x in xs if x not in stop_words])\n",
    "\n",
    "test['morph'] = test['data'].apply(tokenizer, tag=mecab)\n",
    "test['morph'] = test['morph'].apply(lambda xs: [x for x in xs if x not in stop_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단어 사전 만들기 \n",
    "counter = Counter()\n",
    "for sentence in train['morph']:\n",
    "    counter.update(sentence)\n",
    "\n",
    "vocab_f = vocab(counter, min_freq=5, specials=['<unk>','<pad>'])\n",
    "vocab_f.set_default_index(vocab_f['<unk>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/_jit_internal.py:1138: UserWarning: The inner type of a container is lost when calling torch.jit.isinstance in eager mode. For example, List[int] would become list and therefore falsely return True for List[float] or List[str].\n",
      "  warnings.warn(\"The inner type of a container is lost when \"\n"
     ]
    }
   ],
   "source": [
    "# text to num transform\n",
    "text_transform = T.Sequential(\n",
    "    T.VocabTransform(vocab_f),\n",
    "    T.Truncate(max_seq_len=300),\n",
    "    T.ToTensor(padding_value=vocab_f['<pad>'])\n",
    ")\n",
    "\n",
    "preprocess_train_output = text_transform(train['morph'].tolist())\n",
    "preprocess_test_output = text_transform(test['morph'].tolist())\n",
    "\n",
    "label = train.category.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 저장\n",
    "with open('/root/share/data/vocab.pkl','wb') as f:\n",
    "    pickle.dump(vocab_f, f)\n",
    "\n",
    "with open('/root/share/data/train_data.pkl','wb') as f:\n",
    "    pickle.dump(preprocess_train_output, f)\n",
    "\n",
    "with open('/root/share/data/train_label.pkl', 'wb') as f:\n",
    "    pickle.dump(label, f)\n",
    "\n",
    "with open('/root/share/data/test_data.pkl','wb') as f:\n",
    "    pickle.dump(preprocess_test_output, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
