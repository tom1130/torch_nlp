{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from konlpy.tag import Mecab\n",
    "import pickle\n",
    "# torch import\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchtext\n",
    "from collections import Counter\n",
    "from torchtext import transforms as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000\n",
      "5000\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('/root/share/data/train.csv')\n",
    "test = pd.read_csv('/root/share/data/test.csv')\n",
    "print(len(train))\n",
    "print(len(test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train[train['data'].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"'초중고학교 페미니즘교육의무화'중복동의인원 무효처리해 주세요!!. 국민들의 요구를 묵살해도 되나요? 명백한 증거가 있고 부정한 방법을 동원해 목표달성인원을 충족한 해당 청원에 대하여 청와대는 왜 아무런 조치를 취하지 않나요?? 중복 동의된 인원은 무효처리 후 인원 수를 다시 계상해야 정상적이지 않나요?? 청와대가 언제부터 부정한 청원에 대하여 방관하고 용인하였나요??잘못된 부분은 시정하고 바로잡아야 하지 않나요??? 일국의 청와대씩이나 돼 갖고...21만여 표 중에서 중복처리된 부분은 무효처리한 후 다시 숫자를 집계하여 주세요...하물며 정부답변 청원이쟎아요...청와대가 이래서야 되겠습니까??인터넷은 전 세계인이 들락날락하는 공간이에요..어휴, 창피해!!\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['data'][6].replace('\\\\n','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer(sentence, tag):\n",
    "    return tag.morphs(sentence)\n",
    "mecab = Mecab()\n",
    "train['data'] = train['data'].apply(lambda x: x.replace('\\\\n', ''))\n",
    "train['data'] = train['data'].apply(lambda x: x.replace('.', ' '))\n",
    "train['morph'] = train['data'].apply(tokenizer, tag=mecab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = Counter()\n",
    "for sentence in train['morph']:\n",
    "    counter.update(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.vocab import vocab\n",
    "from collections import Counter\n",
    "import torchtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_f = vocab(counter, min_freq=5, specials=['<unk>','<pad>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_f.set_default_index(vocab_f['<unk>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/_jit_internal.py:1138: UserWarning: The inner type of a container is lost when calling torch.jit.isinstance in eager mode. For example, List[int] would become list and therefore falsely return True for List[float] or List[str].\n",
      "  warnings.warn(\"The inner type of a container is lost when \"\n"
     ]
    }
   ],
   "source": [
    "output = T.VocabTransform(vocab_f)(train['morph'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = T.ToTensor(padding_value=vocab_f['<pad>'])(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = T.Truncate(max_seq_len=300)(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([39992, 300])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/_jit_internal.py:1138: UserWarning: The inner type of a container is lost when calling torch.jit.isinstance in eager mode. For example, List[int] would become list and therefore falsely return True for List[float] or List[str].\n",
      "  warnings.warn(\"The inner type of a container is lost when \"\n"
     ]
    }
   ],
   "source": [
    "text_transform = T.Sequential(\n",
    "    T.VocabTransform(vocab_f),\n",
    "    T.Truncate(max_seq_len=300),\n",
    "    T.ToTensor(padding_value=vocab_f['<pad>'])\n",
    ")\n",
    "\n",
    "preprocess_output = text_transform(train['morph'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([39992, 300])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess_output.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = train.category.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('/root/share/data/vocab.pkl','wb') as f:\n",
    "    pickle.dump(vocab_f, f)\n",
    "\n",
    "with open('/root/share/data/train_data.pkl','wb') as f:\n",
    "    pickle.dump(preprocess_output, f)\n",
    "\n",
    "with open('/root/share/data/train_label.pkl', 'wb') as f:\n",
    "    pickle.dump(label, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
