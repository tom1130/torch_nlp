{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":462,"status":"ok","timestamp":1665745054850,"user":{"displayName":"고기호","userId":"09981987576142340132"},"user_tz":-540},"id":"UbmKMLCQkwRl","outputId":"4a2f6603-211c-468b-f310-e59c35fdf59d"},"outputs":[],"source":["# cd /content/drive/MyDrive/commit_folder/chungwadae/torch_nlp"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":3452,"status":"ok","timestamp":1665745058301,"user":{"displayName":"고기호","userId":"09981987576142340132"},"user_tz":-540},"id":"twAwvbzvi_VU"},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n"]}],"source":["# import basic libarary\n","import pandas\n","import pickle\n","import math\n","from tqdm import tqdm\n","\n","# import torch module\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.nn import TransformerEncoder, TransformerEncoderLayer\n","from torch.utils.data import DataLoader, random_split"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1665745058301,"user":{"displayName":"고기호","userId":"09981987576142340132"},"user_tz":-540},"id":"9-XcvJmSDc5s"},"outputs":[],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","computer = 'docker'"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":563,"status":"ok","timestamp":1665722074625,"user":{"displayName":"고기호","userId":"09981987576142340132"},"user_tz":-540},"id":"xgl_H_-Ki_VX"},"outputs":[],"source":["class PositionalEncoding(nn.Module):\n","    def __init__(self, dimension, vocab_size, dropout):\n","        super().__init__()\n","        self.dropout = nn.Dropout(dropout)\n","\n","        pe = torch.zeros(vocab_size, dimension)\n","        position = torch.arange(0, vocab_size, dtype=torch.float).unsqueeze(1)\n","        div_term = torch.exp(\n","            torch.arange(0, dimension, 2).float()*(-math.log(10000.0)/dimension)\n","        )\n","        pe[:, 0::2] = torch.sin(position * div_term)\n","        pe[:, 1::2] = torch.cos(position * div_term)\n","        pe = pe.unsqueeze(0)\n","        self.register_buffer('pe',pe)\n","\n","    def forward(self, x):\n","        x = x + self.pe[:, :x.size(1), :]\n","        return self.dropout(x)\n","\n","class TransoformerClassifierNetwork(nn.Module):\n","    def __init__(self, nhead, dim_feedforward, num_layers, dropout, vocab_size, dimension):\n","        super().__init__()\n","\n","        self.emb = nn.Embedding(vocab_size, dimension)\n","\n","        self.pos_encoder = PositionalEncoding(\n","            dimension = dimension,\n","            dropout = dropout,\n","            vocab_size = vocab_size\n","        )\n","\n","        encoder_layer = TransformerEncoderLayer(\n","            d_model = dimension,\n","            nhead = nhead,\n","            dim_feedforward = dim_feedforward,\n","            dropout = dropout\n","        )\n","\n","        self.transformer_encoder = TransformerEncoder(\n","            encoder_layer,\n","            num_layers = num_layers\n","        )\n","\n","        self.linear = nn.Linear(dimension, 3)\n","        self.dimension = dimension\n","\n","    def forward(self, input):\n","        x = self.emb(input)\n","        # x = self.pos_encoder(x)\n","        x = self.transformer_encoder(x)\n","        x = x.mean(dim=1)\n","        x = self.linear(x)\n","        output = nn.Softmax()(x)\n","        return output\n"]},{"cell_type":"code","execution_count":27,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":246},"executionInfo":{"elapsed":3,"status":"error","timestamp":1665724401658,"user":{"displayName":"고기호","userId":"09981987576142340132"},"user_tz":-540},"id":"FcAauuQ_zJtK","outputId":"ab592eaf-c1c0-451f-f5c9-4b9d8e8d1ed8"},"outputs":[],"source":["class PositionalEncoding(nn.Module):\n","    def __init__(self, dimension, max_len, dropout):\n","        super().__init__()\n","        self.dropout = nn.Dropout(dropout)\n","        self.pos_emb = nn.Embedding(max_len, dimension).float()\n","        self.max_len = max_len\n","    def forward(self, x):\n","        positions = torch.arange(start=0, end=self.max_len, dtype=torch.int)\n","        x = x + self.pos_emb(positions)\n","        return self.dropout(x)\n","\n","class TransoformerClassifierNetwork(nn.Module):\n","    def __init__(self, nhead, dim_feedforward, num_layers, dropout, vocab_size, dimension, max_len):\n","        super().__init__()\n","\n","        self.emb = nn.Embedding(vocab_size, dimension)\n","\n","        self.pos_encoder = PositionalEncoding(\n","            dimension = dimension,\n","            dropout = dropout,\n","            max_len = max_len\n","        )\n","\n","        encoder_layer = TransformerEncoderLayer(\n","            d_model = dimension,\n","            nhead = nhead,\n","            dim_feedforward = dim_feedforward,\n","            dropout = dropout\n","        )\n","\n","        self.transformer_encoder = TransformerEncoder(\n","            encoder_layer,\n","            num_layers = num_layers\n","        )\n","\n","        self.linear = nn.Linear(dimension, 3)\n","        self.dimension = dimension\n","\n","    def forward(self, input):\n","        input = input.float()\n","        x = self.emb(input)\n","        x = self.pos_encoder(x)\n","        x = self.transformer_encoder(x)\n","        x = x.mean(dim=1)\n","        x = self.linear(x)\n","        output = nn.Softmax()(x)\n","        return output"]},{"cell_type":"code","execution_count":28,"metadata":{"executionInfo":{"elapsed":3649,"status":"ok","timestamp":1665745063066,"user":{"displayName":"고기호","userId":"09981987576142340132"},"user_tz":-540},"id":"UHLfI4SbksIL"},"outputs":[],"source":["if computer == 'colab':\n","  train_data_path = 'data/train_data.pkl'\n","  train_label_path = 'data/train_label.pkl'\n","  test_data_path = 'data/test_data.pkl'\n","elif computer == 'docker':\n","  train_data_path = '/root/share/data/train_data.pkl'\n","  train_label_path = '/root/share/data/train_label.pkl'\n","  test_data_path = '/root/share/data/test_data.pkl'\n","\n","with open(train_data_path, 'rb') as f:\n","  train_data = pickle.load(f)\n","\n","with open(train_label_path, 'rb') as f:\n","  train_label = pickle.load(f)\n","\n","with open(test_data_path, 'rb') as f:\n","  test_data = pickle.load(f)"]},{"cell_type":"code","execution_count":29,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1665723852360,"user":{"displayName":"고기호","userId":"09981987576142340132"},"user_tz":-540},"id":"yYn-HqCA-VxP"},"outputs":[],"source":["# train hyperparameters\n","EPOCHS = 50\n","BATCH_SIZE = 128"]},{"cell_type":"code","execution_count":30,"metadata":{"executionInfo":{"elapsed":395,"status":"ok","timestamp":1665723853038,"user":{"displayName":"고기호","userId":"09981987576142340132"},"user_tz":-540},"id":"89IgpRCD-R91"},"outputs":[],"source":["train, valid = random_split([[train_data[i], train_label[i]] for i in range(len(train_label))], [len(train_label)-2000,2000])\n","train_dataloader = DataLoader(train, batch_size=BATCH_SIZE, shuffle=True)\n","test_dataloader = DataLoader(valid, batch_size=BATCH_SIZE, shuffle=False)"]},{"cell_type":"code","execution_count":31,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1665723853318,"user":{"displayName":"고기호","userId":"09981987576142340132"},"user_tz":-540},"id":"D3l0kLTZmoVA"},"outputs":[],"source":["model = TransoformerClassifierNetwork(\n","    nhead = 4,\n","    dim_feedforward = 50,\n","    num_layers = 1,\n","    dropout = 0.2,\n","    vocab_size = 42000,\n","    dimension = 128,\n","    max_len = 300\n",").to(device)\n","loss_function = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(params=model.parameters(), lr=0.001)"]},{"cell_type":"code","execution_count":32,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":453},"executionInfo":{"elapsed":4,"status":"error","timestamp":1665723854217,"user":{"displayName":"고기호","userId":"09981987576142340132"},"user_tz":-540},"id":"cbAt_UlKoW_H","outputId":"b2038f5f-eb62-4abf-e844-889f1b7b90ae"},"outputs":[{"name":"stderr","output_type":"stream","text":["  0%|          | 0/297 [00:00<?, ?it/s]\n"]},{"ename":"RuntimeError","evalue":"Expected tensor for argument #1 'indices' to have one of the following scalar types: Long, Int; but got torch.cuda.FloatTensor instead (while checking arguments for embedding)","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_1264/1768096665.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mepoch_correct\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpredicted\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_1264/3744166026.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0memb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_encoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransformer_encoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    158\u001b[0m         return F.embedding(\n\u001b[1;32m    159\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m             self.norm_type, self.scale_grad_by_freq, self.sparse)\n\u001b[0m\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2197\u001b[0m         \u001b[0;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2198\u001b[0m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2199\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: Expected tensor for argument #1 'indices' to have one of the following scalar types: Long, Int; but got torch.cuda.FloatTensor instead (while checking arguments for embedding)"]}],"source":["for epoch in range(EPOCHS):\n","  epoch_loss = 0\n","  epoch_correct = 0\n","  epoch_count = 0\n","  for i, data in tqdm(enumerate(train_dataloader, 1), total=len(train_dataloader),position=0, leave=True):\n","    inputs, labels = data\n","    inputs = inputs.to(device)\n","    labels = labels.to(device)\n","    optimizer.zero_grad()\n","    outputs = model(inputs)\n","    _, predicted = torch.max(outputs.data, 1)\n","    epoch_correct += (predicted==labels).sum().item()\n","    loss = loss_function(outputs, labels)\n","    loss.backward()\n","    # torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n","    optimizer.step()\n","\n","    epoch_loss += loss.item()\n","    epoch_count += inputs.size(0)\n","    \n","  with torch.no_grad():\n","    test_epoch_loss = 0\n","    test_epoch_correct = 0\n","    test_epoch_count = 0\n","\n","    for i, data in enumerate(test_dataloader, 1):\n","      inputs, labels = data\n","      inputs = inputs.to(device)\n","      labels = labels.to(device)\n","      outputs = model(inputs)\n","      _, predicted = torch.max(outputs.data, 1)\n","      test_epoch_correct += (predicted==labels).sum().item()\n","      loss = loss_function(outputs, labels)\n","      test_epoch_loss += loss.item()\n","      test_epoch_count += inputs.size(0)\n","  print(f'train : epoch={epoch}, loss={epoch_loss:.4f}, accuracy={epoch_correct/epoch_count:.4f}')\n","  print(f'valid : loss={test_epoch_loss:.4f}, accuracy={test_epoch_correct/test_epoch_count:.4f}')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"c4Yyn7UIJERs"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"provenance":[]},"kernelspec":{"display_name":"Python 3.7.13 ('base')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.13"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"}}},"nbformat":4,"nbformat_minor":0}
